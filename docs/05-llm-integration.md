# LLM連携

## 概要

LangGraph Slide Generatorでは、大規模言語モデル（LLM）をシステムの中核コンポーネントとして活用し、抽出されたテキストの意味理解、コンテンツの構造化、適切なHTML要素への変換を行います。このドキュメントでは、システム内でのLLM活用方法、プロンプト設計、およびLangGraphとの連携について説明します。

## LLMの役割

システム内でのLLMの主な役割は以下の通りです：

1. **コンテンツ理解**
   - 抽出されたテキストの意味的分析
   - 文書の論理構造の把握
   - 専門用語や概念の識別
   - コンテキストに基づく内容の解釈

2. **構造決定**
   - 見出しの階層関係の確立
   - コンテンツブロックの論理的グループ化
   - スライド区切りポイントの最適な位置の判断
   - 関連要素間の関係性の特定

3. **HTML生成補助**
   - 各コンテンツ要素に最適なHTML要素の決定
   - 適切なCSSクラスとスタイルの選択
   - アクセシビリティを考慮したマークアップの生成
   - 数式のMathJax表現への変換支援

## LLM選択基準

システムで利用するLLMの選択には以下の基準を考慮します：

1. **日本語理解能力**
   - 日本語テキストの深い理解
   - 専門用語や学術的内容の理解
   - 日本語特有の文法構造の処理能力

2. **コンテキスト長**
   - 長文ドキュメントの処理に十分なコンテキストウィンドウ
   - 文書全体を考慮した分析が可能な容量

3. **構造化出力能力**
   - 指定された形式（JSON、XMLなど）での出力生成
   - 一貫した構造化データの生成能力

4. **推論速度**
   - 実用的な応答時間での処理能力
   - バッチ処理と並列処理への対応

## プロンプト設計

LLMとの効果的な連携のためのプロンプト設計戦略：

### コンテンツ分析プロンプト

```
あなたは教科書や講義資料から内容を分析するエキスパートAIです。以下の抽出されたテキストを分析し、文書構造を特定してください：

[抽出されたテキスト]

以下の要素を識別してください：
1. タイトルとサブタイトル（存在する場合）
2. 見出し階層（章、セクション、サブセクション）
3. コンテンツブロック（段落、リスト、数式）
4. 特殊要素（注釈、コールアウト、定義）

回答は以下のJSON形式で提供してください：
{
  "title": "文書タイトル",
  "subtitle": "サブタイトル（あれば）",
  "sections": [
    {
      "heading": "セクション見出し",
      "level": 見出しレベル（1〜3）,
      "content_blocks": [
        {
          "type": "paragraph|list|equation|note|definition",
          "content": "コンテンツ本文",
          "metadata": {}
        }
      ]
    }
  ]
}
```

### スライド構造決定プロンプト

```
あなたはプレゼンテーションスライドのデザインエキスパートです。以下の文書構造に基づいて、最適なスライド区切りと構成を決定してください：

[文書構造JSON]

スライド分割にあたり、以下の点を考慮してください：
1. 各スライドは単一のトピックまたは概念を扱うべき
2. 1スライドあたりのテキスト量は適切であるべき
3. 関連する情報はグループ化すべき
4. 論理的な流れを維持すべき

回答は以下のJSON形式で提供してください：
{
  "slides": [
    {
      "type": "title|toc|content|divider",
      "title": "スライドタイトル",
      "content_blocks": [
        {
          "type": "heading|paragraph|list|equation|note",
          "content": "内容",
          "styling": {}
        }
      ]
    }
  ]
}
```

### HTML要素決定プロンプト

```
あなたはHTMLコーディングのエキスパートです。以下のスライド構造に基づいて、各要素に最適なHTML要素とCSSクラスを決定してください：

[スライド構造JSON]

以下の点に注意してください：
1. セマンティックなHTML5要素を使用する
2. アクセシビリティに配慮する
3. レスポンシブデザインの原則に従う
4. 数式にはMathJax互換の記法を使用する

回答は以下のJSON形式で提供してください：
{
  "html_elements": [
    {
      "content_id": "参照ID",
      "html_tag": "適切なHTMLタグ",
      "css_classes": ["適用するCSSクラス"],
      "attributes": {"属性名": "値"}
    }
  ]
}
```

## LangGraphとの統合

LLMモジュールはLangGraphワークフローの中で以下のように統合されます：

1. **ステートアクセス**: LLMノードは共有状態オブジェクトからデータを受け取り、処理結果を状態に追加します

2. **ノード実装**: 各LLM処理ステップは独立したノードとして実装され、特定の機能に焦点を当てます

3. **条件分岐**: LLMの判断に基づいて、条件付きエッジを通じてワークフローの異なる経路に進むことができます

4. **記憶管理**: 複雑な文書では複数の処理ステップにわたって文脈や解析結果を維持します

## LLM統合アーキテクチャ

LLMモジュールのアーキテクチャ概要：

```
入力データ → 前処理 → プロンプト生成 → LLM呼び出し → 応答解析 → 結果構造化 → 状態更新
```

### コンポーネント詳細

1. **プロンプトマネージャ**
   - プロンプトテンプレートの管理
   - コンテキスト依存のプロンプト生成
   - テンプレート変数の挿入

2. **LLMコネクタ**
   - 各LLMサービスへの統一インターフェース
   - 認証と接続管理
   - リクエスト・レスポンスのフォーマット処理

3. **応答プロセッサ**
   - LLM応答の解析と検証
   - 構造化データへの変換
   - エラー処理とフォールバックメカニズム

4. **キャッシュマネージャ**
   - 類似クエリの結果キャッシュ
   - 処理効率の最適化
   - コスト管理

## 最適化戦略

LLM使用の効率化とコスト最適化のための戦略：

1. **バッチ処理**
   - 可能な場合、複数のクエリをバッチで処理
   - 一度のLLM呼び出しで複数の要素を分析

2. **キャッシング**
   - 一般的なパターンに対する応答をキャッシュ
   - 計算結果の再利用による効率化

3. **段階的処理**
   - 最初は高レベルの構造を把握し、必要に応じて詳細分析
   - 階層的なアプローチによるコンテキスト最適化

4. **フォールバック機構**
   - 主要LLMが失敗した場合の代替モデルの使用
   - 特殊ケース用の専用プロンプトとモデル

## 課題と対策

LLM統合における課題と対策：

### 精度の一貫性

**課題**: LLM応答のばらつきによる結果の不安定性

**対策**:
- 詳細な指示と具体例を含むプロンプト設計
- 構造化出力フォーマットの厳格な指定
- 応答の検証と必要に応じたリトライ

### コンテキスト制限

**課題**: 長い文書全体を一度に処理できないコンテキスト制限

**対策**:
- 文書の分割と段階的処理
- 重要情報の要約と保持
- コンテキスト管理の最適化

### 専門知識の処理

**課題**: 特定分野の専門的内容の理解の限界

**対策**:
- ドメイン特化プロンプトの開発
- 専門用語辞書の統合
- 専門分野別の微調整モデルの検討

### 処理速度とコスト

**課題**: LLM呼び出しによる処理時間とコストの増加

**対策**:
- 必要最小限のLLM呼び出し設計
- キャッシュとバッチ処理の積極活用
- 重要度に応じたモデル選択（小規模/大規模）

## LLM選択肢

現在検討中のLLMオプション：

1. **GPT-4/GPT-4 Turbo**
   - 長いコンテキスト処理能力
   - 高度な日本語理解
   - 優れた構造化出力能力
   - 比較的高価なAPI料金

2. **Claude 3**
   - 優れた指示遵守能力
   - 長文コンテキスト処理
   - 良好な日本語処理能力
   - 多様な出力フォーマット対応

3. **Gemini Pro/Ultra**
   - コスト効率の良いパフォーマンス
   - 長文処理能力
   - 多言語サポート
   - 構造化データ生成能力

4. **オープンソースモデル（Llama 3, MPT, Mixtral, 等）**
   - 自己ホスティングオプション
   - カスタマイズ可能性
   - コスト効率
   - モデルサイズに応じたパフォーマンス

## モニタリングと改善

LLM統合の継続的な最適化のためのアプローチ：

1. **パフォーマンス測定**
   - LLM応答の精度評価
   - 処理時間とリソース使用量の追跡
   - エラーパターンの分析

2. **プロンプト最適化**
   - A/Bテストによるプロンプト改善
   - エッジケースのための特殊プロンプト開発
   - 継続的なプロンプト調整

3. **フィードバックループ**
   - 処理結果の人間レビューからのフィードバック
   - 失敗ケースの収集と分析
   - 成功パターンの強化

4. **モデル更新追跡**
   - 新しいLLMバージョンの評価
   - パフォーマンス向上のためのモデル切り替え
   - マルチモデルアプローチの検討
